{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team: HáLab\n",
    "\n",
    "Team members: Stumphauser Nóra, Lestyan Bence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load the images and labels\n",
    "images = np.load('images.npy')\n",
    "label = pd.read_csv('label.csv')\n",
    "label = label.drop(label.columns[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the train, valid and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, label['label'], test_size=0.30, random_state=42)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2802 601 601\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_valid), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2802 601 601\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train), len(y_valid), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2802, 7, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2802,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the images, because input shape of KERAS is 3-dimentional, so we need the \"channel dimension\" (it is 1)\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_valid = x_valid.reshape(x_valid.shape + (1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#defining early stopping, model checkpoint to save best models and reduce LR\n",
    "earlyStopping = EarlyStopping(monitor='val_AUC', patience=10, verbose=0, mode='max')\n",
    "mcp_save = ModelCheckpoint('models/BEST.mdl_wts.hdf5', save_best_only=True, monitor='val_AUC', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_AUC', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First model - basic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we constructed a \"random\" model (random = not a very special)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size =(3, 3), strides =(1, 1), activation ='relu',input_shape=(7, 24, 1))) \n",
    "#model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "model.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "#model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128, activation ='relu')) \n",
    "model.add(Dense(1, activation ='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 5, 22, 32)         320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 20, 64)         18496     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 203,457\n",
      "Trainable params: 203,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2802 samples, validate on 601 samples\n",
      "Epoch 1/40\n",
      "2802/2802 - 2s - loss: 3.9966 - AUC: 0.4880 - val_loss: 0.7239 - val_AUC: 0.4887\n",
      "Epoch 2/40\n",
      "2802/2802 - 1s - loss: 0.7099 - AUC: 0.5198 - val_loss: 0.6903 - val_AUC: 0.5477\n",
      "Epoch 3/40\n",
      "2802/2802 - 1s - loss: 0.6810 - AUC: 0.5846 - val_loss: 0.6897 - val_AUC: 0.5831\n",
      "Epoch 4/40\n",
      "2802/2802 - 1s - loss: 0.6664 - AUC: 0.6276 - val_loss: 0.6690 - val_AUC: 0.6207\n",
      "Epoch 5/40\n",
      "2802/2802 - 1s - loss: 0.6396 - AUC: 0.6791 - val_loss: 0.6640 - val_AUC: 0.6501\n",
      "Epoch 6/40\n",
      "2802/2802 - 1s - loss: 0.6265 - AUC: 0.6981 - val_loss: 0.6639 - val_AUC: 0.6513\n",
      "Epoch 7/40\n",
      "2802/2802 - 1s - loss: 0.6085 - AUC: 0.7223 - val_loss: 0.6413 - val_AUC: 0.6783\n",
      "Epoch 8/40\n",
      "2802/2802 - 1s - loss: 0.6011 - AUC: 0.7302 - val_loss: 0.6471 - val_AUC: 0.6727\n",
      "Epoch 9/40\n",
      "2802/2802 - 1s - loss: 0.5868 - AUC: 0.7489 - val_loss: 0.6703 - val_AUC: 0.6608\n",
      "Epoch 10/40\n",
      "2802/2802 - 1s - loss: 0.5773 - AUC: 0.7598 - val_loss: 0.6516 - val_AUC: 0.6731\n",
      "Epoch 11/40\n",
      "2802/2802 - 1s - loss: 0.5724 - AUC: 0.7662 - val_loss: 0.6572 - val_AUC: 0.6758\n",
      "Epoch 12/40\n",
      "2802/2802 - 1s - loss: 0.5584 - AUC: 0.7787 - val_loss: 0.6642 - val_AUC: 0.6831\n",
      "Epoch 13/40\n",
      "2802/2802 - 1s - loss: 0.5517 - AUC: 0.7850 - val_loss: 0.6553 - val_AUC: 0.6950\n",
      "Epoch 14/40\n",
      "2802/2802 - 1s - loss: 0.5393 - AUC: 0.7949 - val_loss: 0.6635 - val_AUC: 0.6758\n",
      "Epoch 15/40\n",
      "2802/2802 - 1s - loss: 0.5607 - AUC: 0.7759 - val_loss: 0.6964 - val_AUC: 0.6658\n",
      "Epoch 16/40\n",
      "2802/2802 - 1s - loss: 0.5462 - AUC: 0.7880 - val_loss: 0.6920 - val_AUC: 0.6643\n",
      "Epoch 17/40\n",
      "2802/2802 - 1s - loss: 0.5525 - AUC: 0.7844 - val_loss: 0.6749 - val_AUC: 0.6828\n",
      "Epoch 18/40\n",
      "2802/2802 - 1s - loss: 0.5363 - AUC: 0.8006 - val_loss: 0.6784 - val_AUC: 0.6657\n",
      "Epoch 19/40\n",
      "2802/2802 - 1s - loss: 0.5158 - AUC: 0.8167 - val_loss: 0.6842 - val_AUC: 0.6739\n",
      "Epoch 20/40\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2802/2802 - 1s - loss: 0.5103 - AUC: 0.8246 - val_loss: 0.7126 - val_AUC: 0.6606\n",
      "Epoch 21/40\n",
      "2802/2802 - 1s - loss: 0.4747 - AUC: 0.8564 - val_loss: 0.7201 - val_AUC: 0.6600\n",
      "Epoch 22/40\n",
      "2802/2802 - 1s - loss: 0.4638 - AUC: 0.8627 - val_loss: 0.7110 - val_AUC: 0.6650\n",
      "Epoch 23/40\n",
      "2802/2802 - 1s - loss: 0.4577 - AUC: 0.8670 - val_loss: 0.7150 - val_AUC: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2237215a508>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we training the model with callbacks\n",
    "model.fit(x_train, y_train, batch_size=120, epochs=40, validation_data=(x_valid,y_valid), verbose=2, callbacks=[earlyStopping, mcp_save, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test data - last step: 0.70935297\n",
      "AUC on test data - best model: 0.7024112\n"
     ]
    }
   ],
   "source": [
    "# let see AUC on test data\n",
    "print('AUC on test data - last step:',model.evaluate(x_test, y_test, verbose=0)[1])\n",
    "model4 = tf.keras.models.load_model('models/BEST.mdl_wts.hdf5')\n",
    "print('AUC on test data - best model:',model4.evaluate(x_test, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can manually save the model, if it is goood enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/custom_train86_test71.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second model - DL-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is a modified DL-1 model from https://arxiv.org/ftp/arxiv/papers/1604/1604.05377.pdf\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(128, kernel_size = (1, 5), strides = (1, 1), activation ='relu',input_shape=(7, 24, 1))) \n",
    "model2.add(Conv2D(64, kernel_size = (7, 1), strides = (1, 1), activation ='relu'))\n",
    "model2.add(MaxPooling2D(pool_size =(1, 2))) \n",
    "model2.add(Flatten()) \n",
    "model2.add(Dense(256, activation ='relu')) \n",
    "model2.add(Dense(1, activation ='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 7, 20, 128)        768       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 20, 64)         57408     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 10, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               164096    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 222,529\n",
      "Trainable params: 222,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2802 samples, validate on 601 samples\n",
      "Epoch 1/40\n",
      "2802/2802 - 2s - loss: 4.8636 - AUC: 0.4855 - val_loss: 0.7287 - val_AUC: 0.5425\n",
      "Epoch 2/40\n",
      "2802/2802 - 1s - loss: 0.6943 - AUC: 0.5461 - val_loss: 0.6929 - val_AUC: 0.5446\n",
      "Epoch 3/40\n",
      "2802/2802 - 1s - loss: 0.6783 - AUC: 0.5960 - val_loss: 0.6879 - val_AUC: 0.5792\n",
      "Epoch 4/40\n",
      "2802/2802 - 1s - loss: 0.6653 - AUC: 0.6349 - val_loss: 0.6833 - val_AUC: 0.5992\n",
      "Epoch 5/40\n",
      "2802/2802 - 1s - loss: 0.6561 - AUC: 0.6464 - val_loss: 0.6753 - val_AUC: 0.6144\n",
      "Epoch 6/40\n",
      "2802/2802 - 1s - loss: 0.6366 - AUC: 0.6847 - val_loss: 0.6690 - val_AUC: 0.6384\n",
      "Epoch 7/40\n",
      "2802/2802 - 1s - loss: 0.6153 - AUC: 0.7151 - val_loss: 0.6851 - val_AUC: 0.6328\n",
      "Epoch 8/40\n",
      "2802/2802 - 1s - loss: 0.5915 - AUC: 0.7485 - val_loss: 0.6863 - val_AUC: 0.6366\n",
      "Epoch 9/40\n",
      "2802/2802 - 1s - loss: 0.5680 - AUC: 0.7710 - val_loss: 0.6782 - val_AUC: 0.6544\n",
      "Epoch 10/40\n",
      "2802/2802 - 1s - loss: 0.5652 - AUC: 0.7739 - val_loss: 0.6823 - val_AUC: 0.6393\n",
      "Epoch 11/40\n",
      "2802/2802 - 1s - loss: 0.5558 - AUC: 0.7825 - val_loss: 0.7058 - val_AUC: 0.6272\n",
      "Epoch 12/40\n",
      "2802/2802 - 1s - loss: 0.5298 - AUC: 0.8104 - val_loss: 0.7207 - val_AUC: 0.6474\n",
      "Epoch 13/40\n",
      "2802/2802 - 1s - loss: 0.5225 - AUC: 0.8169 - val_loss: 0.7442 - val_AUC: 0.6211\n",
      "Epoch 14/40\n",
      "2802/2802 - 1s - loss: 0.5065 - AUC: 0.8290 - val_loss: 0.7389 - val_AUC: 0.6413\n",
      "Epoch 15/40\n",
      "2802/2802 - 1s - loss: 0.4846 - AUC: 0.8465 - val_loss: 0.7363 - val_AUC: 0.6588\n",
      "Epoch 16/40\n",
      "2802/2802 - 1s - loss: 0.4689 - AUC: 0.8573 - val_loss: 0.7710 - val_AUC: 0.6426\n",
      "Epoch 17/40\n",
      "2802/2802 - 1s - loss: 0.4466 - AUC: 0.8738 - val_loss: 0.7766 - val_AUC: 0.6374\n",
      "Epoch 18/40\n",
      "2802/2802 - 1s - loss: 0.4462 - AUC: 0.8718 - val_loss: 0.7897 - val_AUC: 0.6295\n",
      "Epoch 19/40\n",
      "2802/2802 - 1s - loss: 0.4229 - AUC: 0.8876 - val_loss: 0.8069 - val_AUC: 0.6348\n",
      "Epoch 20/40\n",
      "2802/2802 - 1s - loss: 0.4101 - AUC: 0.8951 - val_loss: 0.8370 - val_AUC: 0.6315\n",
      "Epoch 21/40\n",
      "2802/2802 - 1s - loss: 0.4012 - AUC: 0.9001 - val_loss: 0.8118 - val_AUC: 0.6511\n",
      "Epoch 22/40\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2802/2802 - 1s - loss: 0.3677 - AUC: 0.9192 - val_loss: 0.9280 - val_AUC: 0.6383\n",
      "Epoch 23/40\n",
      "2802/2802 - 1s - loss: 0.3369 - AUC: 0.9363 - val_loss: 0.8968 - val_AUC: 0.6368\n",
      "Epoch 24/40\n",
      "2802/2802 - 1s - loss: 0.3102 - AUC: 0.9505 - val_loss: 0.9009 - val_AUC: 0.6370\n",
      "Epoch 25/40\n",
      "2802/2802 - 1s - loss: 0.3024 - AUC: 0.9534 - val_loss: 0.9011 - val_AUC: 0.6357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22376328a08>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size=120, epochs=40, validation_data=(x_valid,y_valid), verbose=2, callbacks=[earlyStopping, mcp_save, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test data - last step: 0.69707406\n",
      "AUC on test data - best model: 0.7024112\n"
     ]
    }
   ],
   "source": [
    "print('AUC on test data - last step:',model2.evaluate(x_test, y_test, verbose=0)[1])\n",
    "model4 = tf.keras.models.load_model('models/BEST.mdl_wts.hdf5')\n",
    "print('AUC on test data - best model:',model4.evaluate(x_test, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model2.save(\"models/dl-1_train88_test71.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third model - DL-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is a modified DL-2 model from https://arxiv.org/ftp/arxiv/papers/1604/1604.05377.pdf\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(128, kernel_size = (2, 10), strides = (1, 1), activation ='relu',input_shape=(7, 24, 1))) \n",
    "#model3.add(Dropout(0.25))\n",
    "#model3.add(MaxPooling2D(pool_size =(1, 2))) \n",
    "model3.add(Conv2D(64, kernel_size = (6, 1), strides = (1, 1), activation ='relu'))\n",
    "model3.add(MaxPooling2D(pool_size =(1, 2))) \n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Flatten()) \n",
    "model3.add(Dense(128, activation ='relu')) \n",
    "model3.add(Dropout(0.2))\n",
    "#model3.add(Dense(64, activation ='relu')) \n",
    "#model3.add(Dropout(0.2))\n",
    "model3.add(Dense(32, activation ='relu')) \n",
    "#model3.add(Dropout(0.2)) #-\n",
    "model3.add(Dense(1, activation ='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 6, 15, 128)        2688      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 15, 64)         49216     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               57472     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 113,537\n",
      "Trainable params: 113,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2802 samples, validate on 601 samples\n",
      "Epoch 1/150\n",
      "2802/2802 - 2s - loss: 1.8957 - AUC: 0.5116 - val_loss: 0.7150 - val_AUC: 0.4767\n",
      "Epoch 2/150\n",
      "2802/2802 - 0s - loss: 0.7076 - AUC: 0.5047 - val_loss: 0.6922 - val_AUC: 0.4988\n",
      "Epoch 3/150\n",
      "2802/2802 - 0s - loss: 0.6926 - AUC: 0.5115 - val_loss: 0.6914 - val_AUC: 0.5248\n",
      "Epoch 4/150\n",
      "2802/2802 - 0s - loss: 0.6913 - AUC: 0.5388 - val_loss: 0.6903 - val_AUC: 0.5306\n",
      "Epoch 5/150\n",
      "2802/2802 - 0s - loss: 0.6894 - AUC: 0.5403 - val_loss: 0.6918 - val_AUC: 0.5032\n",
      "Epoch 6/150\n",
      "2802/2802 - 0s - loss: 0.6836 - AUC: 0.5524 - val_loss: 0.6893 - val_AUC: 0.5542\n",
      "Epoch 7/150\n",
      "2802/2802 - 0s - loss: 0.6849 - AUC: 0.5848 - val_loss: 0.6852 - val_AUC: 0.5826\n",
      "Epoch 8/150\n",
      "2802/2802 - 0s - loss: 0.6900 - AUC: 0.5502 - val_loss: 0.6903 - val_AUC: 0.5347\n",
      "Epoch 9/150\n",
      "2802/2802 - 0s - loss: 0.6787 - AUC: 0.5774 - val_loss: 0.6934 - val_AUC: 0.5518\n",
      "Epoch 10/150\n",
      "2802/2802 - 0s - loss: 0.6822 - AUC: 0.5766 - val_loss: 0.6912 - val_AUC: 0.5361\n",
      "Epoch 11/150\n",
      "2802/2802 - 0s - loss: 0.6793 - AUC: 0.5709 - val_loss: 0.6960 - val_AUC: 0.5259\n",
      "Epoch 12/150\n",
      "2802/2802 - 0s - loss: 0.6823 - AUC: 0.5655 - val_loss: 0.6953 - val_AUC: 0.5621\n",
      "Epoch 13/150\n",
      "2802/2802 - 0s - loss: 0.6674 - AUC: 0.6048 - val_loss: 0.6911 - val_AUC: 0.5811\n",
      "Epoch 14/150\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2802/2802 - 0s - loss: 0.6753 - AUC: 0.5939 - val_loss: 0.6956 - val_AUC: 0.5440\n",
      "Epoch 15/150\n",
      "2802/2802 - 0s - loss: 0.6730 - AUC: 0.5943 - val_loss: 0.6875 - val_AUC: 0.5858\n",
      "Epoch 16/150\n",
      "2802/2802 - 0s - loss: 0.6643 - AUC: 0.6162 - val_loss: 0.6882 - val_AUC: 0.5824\n",
      "Epoch 17/150\n",
      "2802/2802 - 0s - loss: 0.6599 - AUC: 0.6170 - val_loss: 0.6939 - val_AUC: 0.5666\n",
      "Epoch 18/150\n",
      "2802/2802 - 0s - loss: 0.6595 - AUC: 0.6248 - val_loss: 0.6922 - val_AUC: 0.5836\n",
      "Epoch 19/150\n",
      "2802/2802 - 0s - loss: 0.6586 - AUC: 0.6291 - val_loss: 0.6897 - val_AUC: 0.5936\n",
      "Epoch 20/150\n",
      "2802/2802 - 0s - loss: 0.6623 - AUC: 0.6272 - val_loss: 0.6879 - val_AUC: 0.5954\n",
      "Epoch 21/150\n",
      "2802/2802 - 0s - loss: 0.6622 - AUC: 0.6260 - val_loss: 0.6897 - val_AUC: 0.5932\n",
      "Epoch 22/150\n",
      "2802/2802 - 0s - loss: 0.6598 - AUC: 0.6293 - val_loss: 0.6903 - val_AUC: 0.6015\n",
      "Epoch 23/150\n",
      "2802/2802 - 0s - loss: 0.6576 - AUC: 0.6311 - val_loss: 0.6887 - val_AUC: 0.6001\n",
      "Epoch 24/150\n",
      "2802/2802 - 0s - loss: 0.6587 - AUC: 0.6316 - val_loss: 0.6893 - val_AUC: 0.6012\n",
      "Epoch 25/150\n",
      "2802/2802 - 0s - loss: 0.6532 - AUC: 0.6464 - val_loss: 0.6879 - val_AUC: 0.6043\n",
      "Epoch 26/150\n",
      "2802/2802 - 0s - loss: 0.6520 - AUC: 0.6463 - val_loss: 0.6893 - val_AUC: 0.6031\n",
      "Epoch 27/150\n",
      "2802/2802 - 0s - loss: 0.6538 - AUC: 0.6425 - val_loss: 0.6915 - val_AUC: 0.5982\n",
      "Epoch 28/150\n",
      "2802/2802 - 0s - loss: 0.6549 - AUC: 0.6342 - val_loss: 0.6879 - val_AUC: 0.6046\n",
      "Epoch 29/150\n",
      "2802/2802 - 0s - loss: 0.6507 - AUC: 0.6496 - val_loss: 0.6885 - val_AUC: 0.6059\n",
      "Epoch 30/150\n",
      "2802/2802 - 0s - loss: 0.6506 - AUC: 0.6456 - val_loss: 0.6880 - val_AUC: 0.6043\n",
      "Epoch 31/150\n",
      "2802/2802 - 0s - loss: 0.6430 - AUC: 0.6662 - val_loss: 0.6883 - val_AUC: 0.6089\n",
      "Epoch 32/150\n",
      "2802/2802 - 0s - loss: 0.6536 - AUC: 0.6428 - val_loss: 0.6867 - val_AUC: 0.6056\n",
      "Epoch 33/150\n",
      "2802/2802 - 0s - loss: 0.6439 - AUC: 0.6623 - val_loss: 0.6866 - val_AUC: 0.6140\n",
      "Epoch 34/150\n",
      "2802/2802 - 0s - loss: 0.6482 - AUC: 0.6568 - val_loss: 0.6900 - val_AUC: 0.6085\n",
      "Epoch 35/150\n",
      "2802/2802 - 0s - loss: 0.6429 - AUC: 0.6586 - val_loss: 0.6906 - val_AUC: 0.6031\n",
      "Epoch 36/150\n",
      "2802/2802 - 0s - loss: 0.6458 - AUC: 0.6500 - val_loss: 0.6911 - val_AUC: 0.6064\n",
      "Epoch 37/150\n",
      "2802/2802 - 0s - loss: 0.6464 - AUC: 0.6482 - val_loss: 0.6909 - val_AUC: 0.6051\n",
      "Epoch 38/150\n",
      "2802/2802 - 0s - loss: 0.6448 - AUC: 0.6536 - val_loss: 0.6895 - val_AUC: 0.6130\n",
      "Epoch 39/150\n",
      "2802/2802 - 0s - loss: 0.6504 - AUC: 0.6475 - val_loss: 0.6904 - val_AUC: 0.6108\n",
      "Epoch 40/150\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "2802/2802 - 0s - loss: 0.6459 - AUC: 0.6503 - val_loss: 0.6914 - val_AUC: 0.6014\n",
      "Epoch 41/150\n",
      "2802/2802 - 0s - loss: 0.6408 - AUC: 0.6705 - val_loss: 0.6906 - val_AUC: 0.6062\n",
      "Epoch 42/150\n",
      "2802/2802 - 0s - loss: 0.6387 - AUC: 0.6687 - val_loss: 0.6904 - val_AUC: 0.6049\n",
      "Epoch 43/150\n",
      "2802/2802 - 0s - loss: 0.6414 - AUC: 0.6632 - val_loss: 0.6909 - val_AUC: 0.6046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22378372c08>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train, y_train, batch_size=120, epochs=150, validation_data=(x_valid,y_valid), verbose=2, callbacks=[earlyStopping, mcp_save, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test data - last step: 0.61160696\n",
      "AUC on test data - best model: 0.7024112\n"
     ]
    }
   ],
   "source": [
    "print('AUC on test data - last step:',model3.evaluate(x_test, y_test, verbose=0)[1])\n",
    "model4 = tf.keras.models.load_model('models/BEST.mdl_wts.hdf5')\n",
    "print('AUC on test data - best model:',model4.evaluate(x_test, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model3.save(\"models/dl-2_train82_test73_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEST.mdl_wts.hdf5',\n",
       " 'custom_train78_test70.h5',\n",
       " 'custom_train86_test71.h5',\n",
       " 'custom_train87_test70.h5',\n",
       " 'dl-1_train85_test69.h5',\n",
       " 'dl-1_train88_test71.h5',\n",
       " 'dl-2_train76_test68.h5',\n",
       " 'dl-2_train80_test72.h5',\n",
       " 'dl-2_train82_test73.h5',\n",
       " 'dl-2_train82_test73_2.h5',\n",
       " 'dl-2_train87_test72.h5',\n",
       " 'dl-2_trainX_test71.hdf5']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have many trained models:  \n",
    "import os\n",
    "modeldir = 'models/'\n",
    "models = os.listdir(modeldir)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/dl-2_train82_test73_2.h5'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldir + models[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEST.mdl_wts.hdf5',\n",
       " 'custom_train78_test70.h5',\n",
       " 'custom_train86_test71.h5',\n",
       " 'custom_train87_test70.h5',\n",
       " 'dl-1_train85_test69.h5',\n",
       " 'dl-1_train88_test71.h5',\n",
       " 'dl-2_train76_test68.h5',\n",
       " 'dl-2_train80_test72.h5',\n",
       " 'dl-2_train82_test73.h5',\n",
       " 'dl-2_train82_test73_2.h5',\n",
       " 'dl-2_train87_test72.h5',\n",
       " 'dl-2_trainX_test71.hdf5']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have these models:\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST.mdl_wts.hdf5 - AUC:  0.7024112\n",
      "custom_train78_test70.h5 - AUC:  0.70122445\n",
      "custom_train86_test71.h5 - AUC:  0.70935297\n",
      "custom_train87_test70.h5 - AUC:  0.70803803\n",
      "dl-1_train85_test69.h5 - AUC:  0.69341934\n",
      "dl-1_train88_test71.h5 - AUC:  0.7133474\n",
      "dl-2_train76_test68.h5 - AUC:  0.6785109\n",
      "dl-2_train80_test72.h5 - AUC:  0.7245231\n",
      "dl-2_train82_test73.h5 - AUC:  0.73281294\n",
      "dl-2_train82_test73_2.h5 - AUC:  0.7352253\n",
      "dl-2_train87_test72.h5 - AUC:  0.7209686\n",
      "dl-2_trainX_test71.hdf5 - AUC:  0.71767056\n"
     ]
    }
   ],
   "source": [
    "# Check the AUC of the saved models\n",
    "for i in range(len(models)):\n",
    "    model4 = tf.keras.models.load_model(modeldir + models[i])\n",
    "    print(models[i], \"- AUC: \", model4.evaluate(x_test, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 7, 20, 256)        1536      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 7, 10, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 1, 10, 128)        229504    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1, 10, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 128)               82048     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 323,457\n",
      "Trainable params: 323,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#This is the  'dl-2_train82_test73_2.h5', so let's see it.\n",
    "model_best = tf.keras.models.load_model(modeldir + models[9])\n",
    "model_best.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a modified DL-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
